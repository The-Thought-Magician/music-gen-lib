# Step 3: AI Note Sequence Models

## Objective

Create Pydantic models that define the structure of AI-generated note sequences. These models validate AI output and provide type-safe data structures for the rendering engine.

## Overview

When the AI generates a composition, it returns JSON that we parse into these models:
- `AINote` - Single note or rest
- `AIPart` - Instrument part (sequence of notes)
- `AIComposition` - Complete composition with metadata

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│  AI Output (JSON)                                           │
│  {                                                           │
│    "title": "Moonlight Sonata",                             │
│    "tempo": 120,                                            │
│    "parts": [...]                                           │
│  }                                                           │
├─────────────────────────────────────────────────────────────┤
│  Pydantic Validation                                        │
│  AIComposition.parse_raw(json_string)                       │
├─────────────────────────────────────────────────────────────┤
│  Validated Python Objects                                   │
│  AIComposition(title=..., tempo=..., parts=[...])           │
└─────────────────────────────────────────────────────────────┘
```

## Tasks

### 3.1 Create AI Models Package

Create `src/musicgen/ai_models/` package structure:
```
src/musicgen/ai_models/
├── __init__.py
├── notes.py       # AINote, AIRest
├── parts.py       # AIPart
└── composition.py # AIComposition
```

### 3.2 Note Models

Create `src/musicgen/ai_models/notes.py`:

```python
"""AI-generated note and rest models."""

from __future__ import annotations
from typing import Union, Optional
from pydantic import BaseModel, Field, field_validator
from enum import Enum


class ArticulationType(str, Enum):
    """Types of articulation markings."""
    STACCATO = "staccato"
    LEGATO = "legato"
    ACCENT = "accent"
    MARCATO = "marcato"
    TENUTO = "tenuto"
    SFORZANDO = "sforzando"


class AINote(BaseModel):
    """A single note generated by AI.

    The AI can specify pitch using:
    - Note name + octave: "C4", "Ab3", "F#5"
    - MIDI number: 60 (C4), 69 (A4)
    - Frequency: 440.0 (A4)
    """

    # Pitch (one of these must be provided)
    note_name: Optional[str] = Field(
        None,
        description="Note name with octave, e.g., 'C4', 'Ab3', 'F#5'",
        pattern=r"^[A-G][#b]?[0-8]$"
    )
    midi_number: Optional[int] = Field(
        None,
        description="MIDI note number (0-127)",
        ge=0,
        le=127
    )
    frequency: Optional[float] = Field(
        None,
        description="Frequency in Hz",
        gt=0
    )

    # Timing
    duration: float = Field(
        ...,
        description="Duration in quarter notes",
        gt=0
    )
    start_time: Optional[float] = Field(
        None,
        description="Start time in quarter notes (if absolute timing)",
        ge=0
    )

    # Velocity/volume
    velocity: int = Field(
        default=80,
        description="MIDI velocity (0-127)",
        ge=0,
        le=127
    )

    # Modifications
    tied: bool = Field(
        default=False,
        description="If True, this note continues to the next"
    )
    articulation: Optional[ArticulationType] = Field(
        None,
        description="Articulation marking"
    )

    @field_validator("note_name")
    @classmethod
    def validate_note_name(cls, v: Optional[str]) -> Optional[str]:
        """Validate note name format."""
        if v is None:
            return None
        # Already validated by regex in Field
        return v.upper() if v else v

    def get_midi_number(self) -> int:
        """Get the MIDI number for this note.

        Converts from note_name or frequency if needed.

        Returns:
            MIDI note number (0-127)
        """
        if self.midi_number is not None:
            return self.midi_number

        if self.note_name is not None:
            # Convert note name to MIDI
            notes = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]
            note = self.note_name[:-1]
            octave = int(self.note_name[-1])

            # Handle flats
            if "b" in note:
                base = note.replace("b", "")
                idx = notes.index(base) - 1
            else:
                idx = notes.index(note)

            return 12 * (octave + 1) + idx

        if self.frequency is not None:
            # Convert frequency to MIDI
            # MIDI = 69 + 12 * log2(freq / 440)
            import math
            return int(round(69 + 12 * math.log2(self.frequency / 440.0)))

        raise ValueError("Note must have note_name, midi_number, or frequency")

    def get_frequency(self) -> float:
        """Get the frequency in Hz.

        Returns:
            Frequency in Hz
        """
        if self.frequency is not None:
            return self.frequency

        midi = self.get_midi_number()
        # f = 440 * 2^((midi-69)/12)
        import math
        return 440.0 * (2.0 ** ((midi - 69) / 12.0))


class AIRest(BaseModel):
    """A rest generated by AI."""

    duration: float = Field(
        ...,
        description="Duration in quarter notes",
        gt=0
    )
    start_time: Optional[float] = Field(
        None,
        description="Start time in quarter notes (if absolute timing)",
        ge=0
    )


# Union type for note events
AINoteEvent = Union[AINote, AIRest]
```

### 3.3 Part Models

Create `src/musicgen/ai_models/parts.py`:

```python
"""AI-generated part models."""

from __future__ import annotations
from typing import List, Union, Optional
from pydantic import BaseModel, Field, field_validator

from musicgen.ai_models.notes import AINote, AIRest, AINoteEvent


class InstrumentRole(str, Field):
    """Role of an instrument in the composition."""
    MELODY = "melody"
    HARMONY = "harmony"
    BASS = "bass"
    ACCOMPANIMENT = "accompaniment"
    COUNTERMELODY = "countermelody"
    PAD = "pad"
    PERCUSSION = "percussion"


class AIPart(BaseModel):
    """An instrument part generated by AI.

    Contains a sequence of notes for a single instrument.
    """

    # Instrument identification
    name: str = Field(
        ...,
        description="Instrument name (e.g., 'violin', 'piano', 'flute')"
    )
    midi_program: int = Field(
        ...,
        description="MIDI program number (0-127)",
        ge=0,
        le=127
    )
    midi_channel: int = Field(
        default=0,
        description="MIDI channel (0-15, 10 for percussion)",
        ge=0,
        le=15
    )

    # Role
    role: InstrumentRole = Field(
        default=InstrumentRole.MELODY,
        description="Role this part plays in the composition"
    )

    # Notes
    notes: List[dict] = Field(
        default_factory=list,
        description="List of note/rest objects (will be validated as AINoteEvent)"
    )

    # Optional dynamics
    dynamics_marking: Optional[str] = Field(
        None,
        description="Dynamic marking (pp, p, mp, mf, f, ff, fff)"
    )
    volume_adjustment: int = Field(
        default=0,
        description="Volume adjustment in decibels (-127 to 127)",
        ge=-127,
        le=127
    )

    # Optional articulation defaults
    default_articulation: Optional[str] = Field(
        None,
        description="Default articulation for notes in this part"
    )

    @field_validator("notes", mode="before")
    @classmethod
    def validate_notes(cls, v: List) -> List:
        """Validate and convert note dictionaries."""
        validated = []
        for note in v:
            if isinstance(note, dict):
                # Check if it's a rest
                if note.get("rest") is True:
                    validated.append(AIRest(**note))
                else:
                    validated.append(AINote(**note))
            else:
                validated.append(note)
        return validated

    def get_note_events(self) -> List[AINoteEvent]:
        """Get validated note events.

        Returns:
            List of AINote and AIRest objects
        """
        events = []
        for note in self.notes:
            if isinstance(note, dict):
                if note.get("rest") is True:
                    events.append(AIRest(**note))
                else:
                    events.append(AINote(**note))
            elif isinstance(note, (AINote, AIRest)):
                events.append(note)
        return events

    @property
    def duration_quarters(self) -> float:
        """Get total duration in quarter notes.

        Returns:
            Total duration
        """
        return sum(
            n.duration if hasattr(n, "duration") else 0
            for n in self.get_note_events()
        )
```

### 3.4 Composition Models

Create `src/musicgen/ai_models/composition.py`:

```python
"""AI-generated composition models."""

from __future__ import annotations
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field, field_validator

from musicgen.ai_models.parts import AIPart


class TimeSignature(BaseModel):
    """Time signature."""

    numerator: int = Field(default=4, ge=1, le=32)
    denominator: int = Field(default=4, ge=1, le=32)

    def __str__(self) -> str:
        return f"{self.numerator}/{self.denominator}"


class KeySignature(BaseModel):
    """Key signature."""

    tonic: str = Field(..., description="Tonic note (e.g., 'C', 'F#', 'Bb')")
    mode: str = Field(
        default="major",
        description="Mode (major, minor, dorian, phrygian, etc.)"
    )

    def __str__(self) -> str:
        return f"{self.tonic} {self.mode}"


class AIComposition(BaseModel):
    """A complete composition generated by AI.

    This is the main model that validates AI output.
    """

    # Metadata
    title: str = Field(..., description="Composition title")
    composer: Optional[str] = Field(None, description="Composer name")

    # Timing
    tempo: int = Field(
        ...,
        description="Tempo in BPM",
        ge=40,
        le=300
    )
    time_signature: TimeSignature = Field(
        default_factory=lambda: TimeSignature(),
        description="Time signature"
    )

    # Key
    key: KeySignature = Field(
        ...,
        description="Key signature"
    )

    # Parts (instruments and their notes)
    parts: List[AIPart] = Field(
        ...,
        description="Instrument parts",
        min_length=1
    )

    # Form and structure
    form: Optional[str] = Field(
        None,
        description="Musical form (binary, ternary, rondo, sonata, etc.)"
    )
    mood: Optional[str] = Field(
        None,
        description="Mood description"
    )

    # Optional sections with timing
    sections: Optional[List[Dict[str, Any]]] = Field(
        None,
        description="Section definitions with measure ranges"
    )

    # Dynamics
    initial_dynamic: Optional[str] = Field(
        None,
        description="Starting dynamic (pp, p, mp, mf, f, ff, fff)"
    )

    @field_validator("parts")
    @classmethod
    def validate_parts(cls, v: List[AIPart]) -> List[AIPart]:
        """Validate parts."""
        if not v:
            raise ValueError("Composition must have at least one part")

        # Check for duplicate MIDI channels
        channels = [p.midi_channel for p in v]
        if len(channels) != len(set(channels)):
            # Note: Channel 10 can be shared for percussion
            non_percussion = [c for c, p in zip(channels, v) if p.role != "percussion"]
            if len(non_percussion) != len(set(non_percussion)):
                raise ValueError("Duplicate MIDI channels for non-percussion parts")

        return v

    @property
    def duration_quarters(self) -> float:
        """Get duration in quarter notes.

        Returns:
            Duration in quarter notes
        """
        if not self.parts:
            return 0.0
        return max(p.duration_quarters for p in self.parts)

    @property
    def duration_seconds(self) -> float:
        """Get duration in seconds.

        Returns:
            Duration in seconds
        """
        # Duration in seconds = (quarters * 60) / tempo
        return (self.duration_quarters * 60) / self.tempo

    @property
    def instrument_names(self) -> List[str]:
        """Get list of instrument names.

        Returns:
            List of instrument names
        """
        return [p.name for p in self.parts]

    def get_part_by_name(self, name: str) -> Optional[AIPart]:
        """Get a part by instrument name.

        Args:
            name: Instrument name

        Returns:
            AIPart if found, None otherwise
        """
        for part in self.parts:
            if part.name.lower() == name.lower():
                return part
        return None

    def get_melody_parts(self) -> List[AIPart]:
        """Get all parts with melody role.

        Returns:
            List of melody parts
        """
        return [p for p in self.parts if p.role == "melody"]

    def get_bass_parts(self) -> List[AIPart]:
        """Get all parts with bass role.

        Returns:
            List of bass parts
        """
        return [p for p in self.parts if p.role == "bass"]
```

### 3.5 Package Init

Create `src/musicgen/ai_models/__init__.py`:

```python
"""AI-generated composition models.

These models validate AI output and provide type-safe structures.
"""

from musicgen.ai_models.notes import (
    AINote,
    AIRest,
    AINoteEvent,
    ArticulationType,
)
from musicgen.ai_models.parts import (
    AIPart,
    InstrumentRole,
)
from musicgen.ai_models.composition import (
    AIComposition,
    TimeSignature,
    KeySignature,
)

__all__ = [
    # Notes
    "AINote",
    "AIRest",
    "AINoteEvent",
    "ArticulationType",
    # Parts
    "AIPart",
    "InstrumentRole",
    # Composition
    "AIComposition",
    "TimeSignature",
    "KeySignature",
]
```

### 3.6 Update Dependencies

Update `pyproject.toml`:

```toml
[project.dependencies]
pydantic >= 2.0
```

### 3.7 Testing

Create `tests/test_ai_models.py`:

```python
"""Test AI composition models."""

import json
from musicgen.ai_models import (
    AINote,
    AIRest,
    AIPart,
    AIComposition,
    TimeSignature,
    KeySignature,
)


def test_ai_note_validation():
    """Test note validation."""
    # Note with note name
    note = AINote(note_name="C4", duration=1.0)
    assert note.get_midi_number() == 60
    assert note.get_frequency() == 261.63

    # Note with MIDI number
    note2 = AINote(midi_number=69, duration=1.0)
    assert note2.get_midi_number() == 69
    assert note2.get_frequency() == 440.0


def test_ai_part_validation():
    """Test part validation."""
    part = AIPart(
        name="violin",
        midi_program=40,
        midi_channel=0,
        role="melody",
        notes=[
            {"note_name": "C4", "duration": 1.0, "velocity": 80},
            {"note_name": "E4", "duration": 0.5, "velocity": 75},
            {"note_name": "G4", "duration": 1.5, "velocity": 70},
        ]
    )

    assert part.name == "violin"
    assert part.duration_quarters == 3.0


def test_ai_composition_validation():
    """Test composition validation."""
    comp_data = {
        "title": "Test Composition",
        "tempo": 120,
        "time_signature": {"numerator": 4, "denominator": 4},
        "key": {"tonic": "C", "mode": "major"},
        "parts": [
            {
                "name": "piano",
                "midi_program": 0,
                "midi_channel": 0,
                "role": "melody",
                "notes": [
                    {"note_name": "C4", "duration": 1.0},
                    {"note_name": "D4", "duration": 1.0},
                ]
            },
            {
                "name": "bass",
                "midi_program": 32,
                "midi_channel": 1,
                "role": "bass",
                "notes": [
                    {"note_name": "C2", "duration": 2.0},
                ]
            }
        ]
    }

    comp = AIComposition(**comp_data)
    assert comp.title == "Test Composition"
    assert comp.tempo == 120
    assert len(comp.parts) == 2
    assert comp.duration_quarters == 2.0


def test_json_parsing():
    """Test parsing from JSON string."""
    json_str = json.dumps({
        "title": "JSON Test",
        "tempo": 100,
        "key": {"tonic": "F", "mode": "major"},
        "parts": [{
            "name": "flute",
            "midi_program": 73,
            "midi_channel": 0,
            "notes": [
                {"note_name": "F4", "duration": 1.0},
            ]
        }]
    })

    comp = AIComposition.model_validate_json(json_str)
    assert comp.title == "JSON Test"


def test_rest_in_notes():
    """Test rest handling."""
    part = AIPart(
        name="piano",
        midi_program=0,
        notes=[
            {"note_name": "C4", "duration": 1.0},
            {"rest": True, "duration": 0.5},
            {"note_name": "E4", "duration": 1.0},
        ]
    )

    events = part.get_note_events()
    assert len(events) == 3
    assert isinstance(events[0], AINote)
    assert isinstance(events[1], AIRest)
    assert isinstance(events[2], AINote)
```

## Deliverables

- `src/musicgen/ai_models/__init__.py`
- `src/musicgen/ai_models/notes.py`
- `src/musicgen/ai_models/parts.py`
- `src/musicgen/ai_models/composition.py`
- `tests/test_ai_models.py`
- Updated `pyproject.toml`

## Example AI Output Format

```json
{
  "title": "Summer Breeze",
  "composer": "AI Composer",
  "tempo": 95,
  "time_signature": {"numerator": 4, "denominator": 4},
  "key": {"tonic": "G", "mode": "major"},
  "mood": "peaceful, flowing",
  "form": "ABA",
  "parts": [
    {
      "name": "flute",
      "midi_program": 73,
      "midi_channel": 0,
      "role": "melody",
      "notes": [
        {"note_name": "G4", "duration": 1.0, "velocity": 80, "articulation": "legato"},
        {"note_name": "A4", "duration": 0.5, "velocity": 75},
        {"note_name": "B4", "duration": 1.5, "velocity": 78},
        {"rest": true, "duration": 0.5},
        {"note_name": "D5", "duration": 2.0, "velocity": 82}
      ]
    },
    {
      "name": "piano",
      "midi_program": 0,
      "midi_channel": 1,
      "role": "harmony",
      "notes": [
        {"note_name": "G3", "duration": 4.0, "velocity": 60},
        {"note_name": "B3", "duration": 4.0, "velocity": 55},
        {"note_name": "D4", "duration": 4.0, "velocity": 55}
      ]
    }
  ]
}
```

## Next Steps

After completing this step:
- Step 4: Gemini 2.5 Pro client
- Step 5: AI composer (orchestrates prompt + schema → AI → validated output)
